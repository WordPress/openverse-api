from django.contrib.postgres.fields import ArrayField
from django.db import models


class Search(models.Model):

    """
    An individual query with attached results.

    TODO(sarayourfriend): Which fields need indexes? :thinking:
    """

    created_at = models.DateTimeField(
        auto_now=True,
        null=False,
        help_text="The date the query was executed.",
    )

    query_hash = models.CharField(
        # We use SHA256 which only needs 64, but we can leave
        # room for changes (maybe not necessary?)
        max_length=128,
        null=False,
        help_text=("The query hash generated by " "``dead_link_mask.get_query_hash``."),
    )

    query_params = models.JSONField(
        null=False,
        help_text="The query parameters used to execute the query.",
    )

    results = ArrayField(
        # Is this going to be a pain to join to retrieve the providers?
        # If we rely on this approach then we'd probably forever by reliant
        # on catalogue data being duplicated between ES and Postgres API.
        # Maybe that wouldn't be the case if we did weekly extractions
        # of the data from here into the catalogue DB and then did the joining
        # etc, over there? In that case, is there somewhere other than
        # Postgres we can keep the data? Is that option expedient (would we be
        # able to use it in a matter of a week or two so that we can actually
        # benefit from this w/r/t iNaturalist?)
        models.UUIDField(null=False),
        null=False,
        help_text="List of result IDs for the query.",
    )

    page = models.IntegerField(
        null=False,
        help_text=(
            "The page number of the request. "
            "Extracted from ``query_params`` for ease of querying."
        ),
    )
